\documentclass[12pt]{article}
\makeatletter
\newcommand*{\rom}[1]{\expandafter\@slowromancap\romannumeral #1@}
\makeatother
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{tikz-cd}
\usepackage{xcolor}


\begin{document}


\textbf{Exercise}
Let \( \{ E_{i,j} \}_{i<j} \) be the set of all elementary matrices, of this form. \newline
Prove that \( E_{i,j}^{-1}=(b_{l,k}) \) is \( E_{i,j}=(a_{l,k}) \), when we substitute \( a_{i,j}=1 \) with \( b_{i,j}=-1 \) \newline

\textbf{Proof}
We can see that directly from the fact that if we multiply \( E_{i,j}^{-1} \) by \( E_{i,j} \) from the left 
then \( E_{i,j} \) is operating on \( E_{i,j}^{-1} \) by adding row \( j \) to row \(i \) \newline
So, in the product matrix, \( (c_{l,k}) \), in order to have \( 1 \) \newline 
on the main diagonal, we need them to exist on the main diagonal
of \( E_{i,j}^{-1} \), to begin with. Now, in order to have \( c_{i,j}=0 \), we need to have the addition of \( j \) to \( i \)
giving \( c_{i,j}=a_{i,j}+b_{i,j}=0 \Rightarrow b_{i,j}=-a_{i,j}=-1 \) \newline

\textbf{Exercise} Prove that if \( (a_{ij})=E_{i,j}, i<j \) is an elementary matrix, \newline
then \( \forall m \in \mathbb(N), E_{i,j}^m \) is \(E_{i,j} \), but with \( a_{ij}=m \) \newline
$$
	E_{i,j} = \begin{pmatrix} 
	1 & 0 & \dots & 0 & 0 \\
	0 & 1 & \dots & 0 & 0 \\
	0 & 0 & \ddots & 1 & 0 \\
	0 & 0 & \dots & 1 & 0 \\
	0 & 0 & \dots & 0 & 1 \\
	\end{pmatrix}
	\quad
	$$

$$ E_{i,j}^2=E_{i,j} \cdot E_{i,j} $$

Since \( E_{i,j} \) is en elemntary matrix, then it operates on the right matrix
as an addition of row \( j \) to row \( i \) \newline

So, $$
	E_{i,j}^2 = \begin{pmatrix} 
	1 & 0 & \dots & 0 & 0 \\
	0 & 1 & \dots & 0 & 0 \\
	0 & 0 & \ddots & 2 & 0 \\
	0 & 0 & \dots & 1 & 0 \\
	0 & 0 & \dots & 0 & 1 \\
	\end{pmatrix}
	\quad
	$$

We assume this is true for all \( E_{i,j}^m \), now we prove for \( E_{i,j}^{m+1} \)
$$
	E_{i,j}^{m+1} = E_{i,j} \cdot E_{i,j}^{m}=\begin{pmatrix} 
	1 & 0 & \dots & 0 & 0 \\
	0 & 1 & \dots & 0 & 0 \\
	0 & 0 & \ddots & 1 & 0 \\
	0 & 0 & \dots & 1 & 0 \\
	0 & 0 & \dots & 0 & 1 \\
	\end{pmatrix} \cdot \begin{pmatrix} 
	1 & 0 & \dots & 0 & 0 \\
	0 & 1 & \dots & 0 & 0 \\
	0 & 0 & \ddots & 1 & 0 \\
	0 & 0 & \dots & 1 & 0 \\
	0 & 0 & \dots & 0 & 1 \\
	\end{pmatrix}^{m}
	\quad
	$$
(by the assumption)
$$
	=\begin{pmatrix} 
	1 & 0 & \dots & 0 & 0 \\
	0 & 1 & \dots & 0 & 0 \\
	0 & 0 & \ddots & 1 & 0 \\
	0 & 0 & \dots & 1 & 0 \\
	0 & 0 & \dots & 0 & 1 \\
	\end{pmatrix} \cdot \begin{pmatrix} 
	1 & 0 & \dots & 0 & 0 \\
	0 & 1 & \dots & 0 & 0 \\
	0 & 0 & \ddots & m & 0 \\
	0 & 0 & \dots & 1 & 0 \\
	0 & 0 & \dots & 0 & 1 \\
	\end{pmatrix}=\begin{pmatrix} 
	1 & 0 & \dots & 0 & 0 \\
	0 & 1 & \dots & 0 & 0 \\
	0 & 0 & \ddots & m+1 & 0 \\
	0 & 0 & \dots & 1 & 0 \\
	0 & 0 & \dots & 0 & 1 \\
	\end{pmatrix}
	\quad
	$$

\newpage
\underline{\textbf{Commutators of elementary matrices}} \newline

Let \( \{ E_{i,j} \}_{i<j} \) be the set of all elementary matrices of this form. \newline

\textbf{Exercise}
\( (a_{l,m})=E_{i,j}^{-1} \) is the matrix with \( 1 \) on the main diagonal, and \( -1 \) in \( a_{i,j} \) \newline
\textbf{Proof}
We can see that directly from the fact that in order to have \newline \( (c_{l,m})=(a_{l,m}) \cdot (b_{l,m})=E_{i,j} \cdot E_{i,j}^{-1}=I \), \newline
we need to have \( c_{i,j}=0 \), which means that adding row \( j \) to row \( i \), in \( E_{i,j}^{-1} \) (by the left multiplication of \( E_{i,j} \)) \newline
must give \( a_{i,j}+b_{i,j}=c_{i,j}=0 \Rightarrow b_{i,j}=-a_{i,j}=-1 \) \newline

\textbf{Exercise}
\( [E_{i,j},E_{j,k}]=E_{i,k} \) \newline
\textbf{Proof}
\( E_{i,j} \) is operating from left on \( E_{j,k} \) by addition of row \( j \) to row \( i \),
so, the product matrix, \( (a_{l,m})=E_{i,j} \cdot E_{j,k} \) has \( 1 \) on the main diagonal and in \( a_{j,k},a_{i,j},a_{i,k} \) \newline
\( E_{i,j}^{-1} \) is operating from left on \( E_{j,k}^{-1} \) by subtraction of row \( j \) from row \( i \),
so, the product matrix, \( (b_{l,m})=E_{i,j}^{-1} \cdot E_{j,k}^{-1} \) has \( 1 \) on the main diagonal and in \( b_{i,k} \), \newline
and \( -1 \) in \( b_{j,k},b_{i,j} \) \newline
Multiplying \( (a_{l,m}) \cdot (b_{l,m}) \) yields a product matrix, \( (c_{l,m}) \) with \( 1 \) on the main diagonal, and, \newline
since \( a_{i,i}=a_{i,j}=a_{i,k}=1 \), with all other cells in row \( j \) being \(0 \),
and since  \( b_{i,k}=b_{k,k}=1 \), and \( b_{j,k}=-1 \), multiplying row \( (a_{l,m})_{i} \) by column \( (b_{l,m})_{k} \) yields
the value \( c_{i,k}=b_{i,k}+b_{j,k}+b_{k,k}=1-1+1=1 \) \newline
We can see that multiplying \( (a_{l,m})_{i} \cdot (b_{l,m})_{j} \)
yields \( c_{i,j}=a_{i,i} \cdot b_{i,j}+a_{i,j} \cdot b_{j,j}=1 \cdot -1+1 \cdot 1=1-1=0 \) \newline
And, we can see that multiplying \( (a_{l,m})_{j} \cdot (b_{l,m})_{k} \)
yields \( c_{j,k}=a_{j,j} \cdot b_{j,k}+a_{j,k} \cdot b_{k,k}=1 \cdot -1+1 \cdot 1=1-1=0 \)

\textbf{Conclusion} \newline
\( [E_{j,k},E_{i,j}]=E_{j,k} \cdot E_{i,j} \cdot E_{j,k}^{-1} \cdot E_{i,j}^{-1}=
((E_{i,j}^{-1})^{-1} \cdot (E_{j,k}^{-1})^{-1} \cdot E_{i,j}^{-1} \cdot E_{j,k}^{-1})^{-1}= 
(E_{i,j} \cdot E_{j,k} \cdot E_{i,j}^{-1} \cdot E_{j,k}^{-1})^{-1}=[E_{i,j},E_{j,k}]^{-1}  \) \newline

For example, \( n=4 \), \newline
$$ E_{1,2} \cdot E_{2,3}=\begin{pmatrix} 
	1 & 1 & 0 & 0 \\
	0 & 1 & 0 & 0 \\
	0 & 0 & 1 & 0 \\
	0 & 0 & 0 & 1 \\
	\end{pmatrix} \cdot \begin{pmatrix} 
	1 & 0 & 0 & 0 \\
	0 & 1 & 1 & 0 \\
	0 & 0 & 1 & 0 \\
	0 & 0 & 0 & 1 \\
	\end{pmatrix}=\begin{pmatrix} 
	1 & 1 & 1 & 0 \\
	0 & 1 & 1 & 0 \\
	0 & 0 & 1 & 0 \\
	0 & 0 & 0 & 1 \\
	\end{pmatrix} $$
$$  E_{1,2}^{-1} \cdot E_{2,3}^{-1}=\begin{pmatrix} 
	1 & -1 & 0 & 0 \\
	0 & 1 & 0 & 0 \\
	0 & 0 & 1 & 0 \\
	0 & 0 & 0 & 1 \\
	\end{pmatrix} \cdot \begin{pmatrix} 
	1 & 0 & 0 & 0 \\
	0 & 1 & -1 & 0 \\
	0 & 0 & 1 & 0 \\
	0 & 0 & 0 & 1 \\
	\end{pmatrix}=\begin{pmatrix} 
	1 & -1 & 1 & 0 \\
	0 & 1 & -1 & 0 \\
	0 & 0 & 1 & 0 \\
	0 & 0 & 0 & 1 \\
	\end{pmatrix} \newline
$$
$$  [E_{1,2} \cdot E_{2,3}]=E_{1,2} \cdot E_{2,3} \cdot E_{1,2}^{-1} \cdot E_{2,3}^{-1}=$$
$$=\begin{pmatrix} 
	1 & 1 & 1 & 0 \\
	0 & 1 & 1 & 0 \\
	0 & 0 & 1 & 0 \\
	0 & 0 & 0 & 1 \\
	\end{pmatrix} \cdot \begin{pmatrix} 
	1 & -1 & 1 & 0 \\
	0 & 1 & -1 & 0 \\
	0 & 0 & 1 & 0 \\
	0 & 0 & 0 & 1 \\
	\end{pmatrix}=\begin{pmatrix} 
	1 & 0 & 1 & 0 \\
	0 & 1 & 0 & 0 \\
	0 & 0 & 1 & 0 \\
	0 & 0 & 0 & 1 \\
\end{pmatrix}=E_{1,3}$$

\textbf{Exercise}
\( [E_{i,j},E_{l,k}]=I \), where \( j \neq l \) \newline
\textbf{Proof}
\( E_{i,j} \) is operating from left on \( E_{l,k} \) by addition of row \( j \) to row \( i \),
so, the product matrix, \( (a_{n,m}=E_{i,j} \cdot E_{l,k} \) has \( 1 \) on the main diagonal and in \( a_{l,k},a_{i,j} \) \newline
\( E_{i,j}^{-1} \) is operating from left on \( E_{l,k}^{-1} \) by subtraction of row \( j \) from row \( i \),
so, the product matrix, \( (b_{n,m}=E_{i,j}^{-1} \cdot E_{l,k}^{-1} \) has \( 1 \) on the main diagonal, \newline
and \( -1 \) in \( b_{l,k},b_{i,j} \) \newline
We can see that multiplying \( (a_{n,m})_{i} \cdot (b_{n,m})_{j} \)
yields \( c_{i,j}=a_{i,i} \cdot b_{i,j}+a_{i,j} \cdot b_{j,j}=1 \cdot -1+1 \cdot 1=1-1=0 \) \newline
And, we can see that multiplying \( (a_{n,m})_{l} \cdot (b_{n,m})_{k} \)
yields \( c_{l,k}=a_{l,l} \cdot b_{l,k}+a_{l,k} \cdot b_{k,k}=1 \cdot -1+1 \cdot 1=1-1=0 \)


For example, \( n=4 \), \newline
$$ E_{1,2} \cdot E_{3,4}=\begin{pmatrix} 
	1 & 1 & 0 & 0 \\
	0 & 1 & 0 & 0 \\
	0 & 0 & 1 & 0 \\
	0 & 0 & 0 & 1 \\
	\end{pmatrix} \cdot \begin{pmatrix} 
	1 & 0 & 0 & 0 \\
	0 & 1 & 0 & 0 \\
	0 & 0 & 1 & 1 \\
	0 & 0 & 0 & 1 \\
	\end{pmatrix}=\begin{pmatrix} 
	1 & 1 & 0 & 0 \\
	0 & 1 & 0 & 0 \\
	0 & 0 & 1 & 1 \\
	0 & 0 & 0 & 1 \\
	\end{pmatrix} $$
$$  E_{1,2}^{-1} \cdot E_{3,4}^{-1}=\begin{pmatrix} 
	1 & -1 & 0 & 0 \\
	0 & 1 & 0 & 0 \\
	0 & 0 & 1 & 0 \\
	0 & 0 & 0 & 1 \\
	\end{pmatrix} \cdot \begin{pmatrix} 
	1 & 0 & 0 & 0 \\
	0 & 1 & 0 & 0 \\
	0 & 0 & 1 & -1 \\
	0 & 0 & 0 & 1 \\
	\end{pmatrix}=\begin{pmatrix} 
	1 & -1 & 0 & 0 \\
	0 & 1 & 0 & 0 \\
	0 & 0 & 1 & -1 \\
	0 & 0 & 0 & 1 \\
	\end{pmatrix} \newline
$$
$$  [E_{1,2} \cdot E_{3,4}]=E_{1,2} \cdot E_{3,4} \cdot E_{1,2}^{-1} \cdot E_{3,4}^{-1}=$$
$$=\begin{pmatrix} 
	1 & 1 & 0 & 0 \\
	0 & 1 & 0 & 0 \\
	0 & 0 & 1 & 1 \\
	0 & 0 & 0 & 1 \\
	\end{pmatrix} \cdot \begin{pmatrix} 
	1 & -1 & 0 & 0 \\
	0 & 1 & 0 & 0 \\
	0 & 0 & 1 & -1 \\
	0 & 0 & 0 & 1 \\
	\end{pmatrix}=\begin{pmatrix} 
	1 & 0 & 0 & 0 \\
	0 & 1 & 0 & 0 \\
	0 & 0 & 1 & 0 \\
	0 & 0 & 0 & 1 \\
\end{pmatrix}=I$$

\textbf{Conclusion} \newline
\( [E_{i,j},[E_{j,k},E_{k,l}]]=[E_{i,j},E_{j,l}]=E_{i,l} \) \newline
\( [E_{i,j},[E_{j,k},E_{m,l}]], m \neq k=[E_{i,l},I]=I \) \newline
\( [E_{i,m},[E_{j,k},E_{k,l}]], m \neq j=[E_{i,m},E_{j,l}]=I \) \newline

\( \Rightarrow [E_{i_{1},i_{2}},[E_{i_{3},i_{4}},...[E_{i_{n-2},i_{n-1}},E_{i_{n-1},i_{n}}]]=
\begin{cases}
    E_{i_{1},i_{n}},& i_{2k}=i_{2k+1},\forall 1 \leq k \leq \frac{n}{2}-1\\
    I,              & \text{otherwise}
\end{cases}
\)

\textbf{Exercise} \newline
\( \#\{ E_{i,j} \in M_{n}(\mathbb{Z}) \}_{i<j}={n \choose 2} \) \newline

\textbf{Proof} \newline
\( (a_{i,j}=E_{i,j}) \). We need to count the options for \( 1 \) above the main diagonal. \newline
\( a_{l,l}=1, \forall 1 \leq l \leq n \), so, if \( i=l \), we have \( n-l=n-i \) options to choose the column index \( j \). \newline
So, the total number of options for \( i,j \) is \( \sum_{k=1}^{n-1}=\frac{(1 + n-1) \cdot (n-1)}{2}=\frac{n \cdot (n-1)}{2}={n \choose 2} \) \newline

This means that we have \( {n \choose 2}^2 \) commutators of the form \( [E_{i,j},E_{l,k}] \).

\textbf{Exercise} \newline
\( \#\{ [E_{i,j},E_{l,k}] \neq I \in M_{n}(\mathbb{Z}) \}_{i<j}=2 \cdot {n \choose 3} \) \newline

\textbf{Proof} \newline
As shown above, \( [E_{i,j},E_{l,k}] \neq I \Leftrightarrow j = l \) \newline
Which means we're counting all the commutators of the form \( [E_{i,j},E_{j,k}] \). \newline
So, the count of such commutators is based on the number of options to choose \newline
ordered triples \( \{i,j,k\} \) out of the ordered set \( [n]=\{1,2,...,n\} \), which is \( {n \choose 3} \) \newline
But, as already shown above, \( [E_{l,k},E_{i,j}]=[E_{i,j},E_{l,k}]^{-1} \), so, for each triple \( \{i,j,k\} \), we have
two commutators, \( [E_{i,j},E_{j,k}] \) and its inverse, which sum up to \( {n \choose 3} \) pairs of commutators. \newline

For example, \( n=5 \), \newline
$$ (a_{l,k})=E_{i,j}=\begin{pmatrix} 
	1 & a_{1,2} & a_{1,3} & a_{1,4} & a_{1,5} \\
	0 & 1 & a_{2,3} & a_{2,4} & a_{2,5} \\
	0 & 0 & 1 & a_{3,4} & a_{3,5} \\
	0 & 0 & 0 & 1 & a_{4,5} \\
	0 & 0 & 0 & 0 & 1 \\
\end{pmatrix} 
$$
Where \( a_{i,j}=1\), and all other \( a_{l,k}=0 \) \newline
The number of options for choosing \( i,j \), in this case, are \( 1+2+3+4=10={5 \choose 2} \), \newline
so, we have \( 10^2=100 \) commutators. 
The number of triples we can choose from \( [5]=\{1,2,3,4,5\} \) is \newline
\( \#\{\{1,2,3\},\{1,2,4\},\{1,2,5\},\{1,3,4\},\{1,3,5\},\{1,4,5\},\{2,3,4\},\{2,3,5\},\{2,4,5\},\{3,4,5\}\}=10={5 \choose 3} \), \newline
so we have 10 commutators that are not the unit matrix, and their inverse, total \( 20 = 2 \cdot 10=2 \cdot {5 \choose 3} \). \newline

\textbf{Exercise} \newline
Given the set of commutators of elementary matrices of the form \newline \( \{ [E_{i,j},E_{j,k}] \in M_{n}(\mathbb{Z}) \}_{i<j<k} \), \newline
we can divide this set to subsets of the form \newline \( \{ 
\{ [E_{i_{1},j_{1,1}},E_{j_{1,1},k_{1}}], [E_{i_{1},j_{1,2}},E_{j_{1,2},k_{1}}],..., [E_{i_{1},j_{1,l_{1}}},E_{j_{1,l_{1}},k_{1}}] \},..., \newline
\{ [E_{i_{m},j_{m,1}},E_{j_{m,1},k_{1}}],...,[E_{i_{m},j_{m,l_{m}}},E_{j_{m,l_{m}},k_{1}}]\}\} \) \newline 
These subsets are equivalence classes, trivially, since the relation is equality (i.e. \( [E_{i_{l},j_{l,m_{1}}},E_{j_{l,m_{1}},k_{l}}]=
[E_{i_{l},j_{l,m_{2}}},E_{j_{l,m_{2}},k_{l}}],i_{l}<j_{l,m_{1}},j_{l,m_{2}}<k_{l} \)). \newline
Fix \( {i,k},1 \leq i \leq n-1,3\ leq k \leq n \), then all the triples of the form \( \{i,j,k\},i \leq i+1 \leq k-1 \) are in the same equivalence class, \newline
due to the above equality. So, the number of these equivalence classes is \( 2 \cdot {n-1 \choose 2} \) \newline
\textbf{Proof} \newline
By induction on \( n \). For \( n=3 \), we have only one triple, namely \( \{1,2,3\} \), so \( {3-1 \choose 2}={2 \choose 2}=1 \)\newline
For \( n+1 \), we shall observe that if we add one to the upper bound (i.e. \( n \rightarrow n'=n+1 \), \newline
then we add one more equivalence class, for each one of the lower bounds of \( n'-1=n \) (i.e., the index \( i \)). \newline
But we also add a new eqivalence class, whose lower bound is \( i=n+1-2=n-1=n'-2 \), which was not in any equivalence class \newline
for \( n=n'-1 \), since we consider only the triples where \( i \leq n-2 \). So, if we mark \( m_{n} \) as the number of equivalence classes \newline
for \( n \), then we have \( m_{n'}=m_{n+1}=m_{n}+(n-2)+1=m_{n}+n-1 \). But, by the assumption, \( m_{n}={n-1 \choose 2} \), \newline 
so \( m_{n'}=m_{n+1}=m_{n}+n-1={n-1 \choose 2}+n-1=\frac{(n-1) \cdot (n-2)}{2}+n-1=\frac{n^2-3n+2}{2}+n-1=\frac{n^2-3n+2+2n-2}{2}=
\frac{n^2-n}{2}=\frac{n \cdot (n-1)}{2}={n \choose 2}=m_{n+1}=m_{n'} \), and we proved the assumption \newline
 

\end{document}
